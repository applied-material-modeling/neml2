<!-- HTML header for doxygen 1.13.2-->
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
  <meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=11" />
  <meta name="generator" content="Doxygen 1.16.1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>NEML2: Scheduler</title>
  <link href="tabs.css" rel="stylesheet" type="text/css" />
  <script type="text/javascript" src="jquery.js"></script>
  <script type="text/javascript" src="dynsections.js"></script>
  <script type="text/javascript" src="clipboard.js"></script>
  <link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript" src="cookie.js"></script>
  <link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
  <script type="text/javascript">
window.MathJax = {
  options: {
    ignoreHtmlClass: 'tex2jax_ignore',
    processHtmlClass: 'tex2jax_process'
  }
};
window.MathJax = {
  loader: {load: ['[tex]/ams', '[tex]/physics', '[tex]/boldsymbol']},
  tex: {packages: {'[+]': ['ams', 'physics', 'boldsymbol']},
        tags: 'ams'}
};
</script>
<script type="text/javascript" id="MathJax-script" async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
  <link href="doxygen.css" rel="stylesheet" type="text/css" />
  <link href="doxygen-awesome.css" rel="stylesheet" type="text/css"/>
<link href="doxygen-awesome-sidebar-only.css" rel="stylesheet" type="text/css"/>
<link href="doxygen-awesome-sidebar-only-darkmode-toggle.css" rel="stylesheet" type="text/css"/>
<link href="doxygen-awesome-tabs.js" rel="stylesheet" type="text/css"/>
<link href="custom.css" rel="stylesheet" type="text/css"/>
  <script type="text/javascript" src="doxygen-awesome-darkmode-toggle.js"></script>
  <script type="text/javascript" src="doxygen-awesome-paragraph-link.js"></script>
  <script type="text/javascript" src="doxygen-awesome-tabs.js"></script>
  <script type="text/javascript" src="doxygen-awesome-interactive-toc.js"></script>
  <!-- Demo animations -->
  <script type="text/javascript" src="anime.min.js"></script>
  <script type="text/javascript" src="work-dispatcher.js"></script>
  <script type="text/javascript" src="static-hybrid-scheduler.js"></script>
  <script type="text/javascript" src="simple-scheduler-demo.js"></script>
  <script type="text/javascript" src="static-hybrid-scheduler-demo.js"></script>
  <script type="text/javascript">
    DoxygenAwesomeDarkModeToggle.init();
    DoxygenAwesomeParagraphLink.init();
    DoxygenAwesomeInteractiveToc.init();
    DoxygenAwesomeTabs.init();
    SimpleSchedulerDemo.init();
    StaticHybridSchedulerDemo.init();
  </script>
</head>
<body>
    <div id="top"><!-- do not remove this div, it is closed by doxygen! -->
      <div id="titlearea">
        <table cellspacing="0" cellpadding="0">
          <tbody>
            <tr id="projectrow">
              <td id="projectalign">
                <div id="projectname">NEML2<span
                    id="projectnumber">&#160;2.0.0</span>
                </div>
              </td>
            </tr>
          </tbody>
        </table>
      </div>
      <!-- end header part -->
<!-- Generated by Doxygen 1.16.1 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search/",'.html');
</script>
<script type="text/javascript">
$(function() { codefold.init(); });
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search',true);
  $(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(function(){initNavTree('system-schedulers.html','',''); });
</script>
<div id="container">
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">Scheduler </div></div>
</div><!--header-->
<div class="contents">
<div class="toc"><h3>Table of Contents</h3>
<ul>
  <li class="level1">
    <a href="#autotoc_md70">Heterogeneous computing </a>
  </li>
  <li class="level1">
    <a href="#autotoc_md71">Work dispatchers </a>
  </li>
  <li class="level1">
    <a href="#autotoc_md72">Work schedulers </a>
    <ul>
      <li class="level2">
        <a href="#autotoc_md73">SimpleScheduler </a>
      </li>
      <li class="level2">
        <a href="#autotoc_md74">SimpleMPIScheduler </a>
      </li>
      <li class="level2">
        <a href="#autotoc_md75">StaticHybridScheduler </a>
      </li>
    </ul>
  </li>
  <li class="level1">
    <a href="#autotoc_md76">Event tracing </a>
  </li>
</ul>
</div>
<div class="textblock"><p><a class="anchor" id="md_build_2doc_2content_2system_2scheduler"></a></p>
<h1 class="doxsection"><a class="anchor" id="autotoc_md70"></a>
Heterogeneous computing</h1>
<p>Modern computing architectures are typically heterogenous: the computing power on a node is divided across multiple asymmetric computing devices. A typical example is a cluster where each node includes one or more CPUs, providing compute with multiple threads that all share memory, and one or more GPUs, which may or may not share memory with each other and the CPUs. NEML2 provides software infrastructure to efficiently divide, send, recover, and merge batched constitutive model updates across multiple asymmetric compute devices.</p>
<dl class="section note"><dt>Note</dt><dd>Currently NEML2 only supports CPU and CUDA compute devices. Additional accelerators supported by pytorch including Apple <a href="https://pytorch.org/docs/stable/mps.html">mps</a> and Intel <a href="https://pytorch.org/docs/stable/xpu.html">xpu</a> may also work, but are not officially supported.</dd></dl>
<p>NEML2 manages work scheduling, dispatch, and joining with two types of objects: dispatchers and schedulers. These objects divide up work along a single batch axis by subdividing that axis into smaller chunks (sub-batches) to run on a given device.</p>
<h1 class="doxsection"><a class="anchor" id="autotoc_md71"></a>
Work dispatchers</h1>
<p>NEML2 currently only has a single type of work dispatcher with two general types of behavior. The calling program (for example in NEML2 itself the driver routine) selects which behavior it wants by invoking the dispatcher with either the <span class="tt">run_async</span> or <span class="tt">run_sync</span> methods. The NEML2 driver routines can use either method, controlled by the <span class="tt">async_dispatch</span> option to the driver.</p>
<p>When calling <span class="tt">run_async</span> the dispatcher maintains a main thread which schedules and distributes work according the algorithm provided by the selected work scheduler. The main thread dispatches the work to a thread pool that maintains a specific thread for each device. The thread picks up the task (representing a batch of work), sends the work to the device, and returns the work, once completed, to the main thread.</p>
<p>With <span class="tt">run_sync</span> the dispatcher schedules work per the scheduler but only runs work sequentially with the single, main NEML2 thread. This model does not provide parallel execution on multiple devices but it's useful for debugging schedulers and functions adequately for schedulers only sending work to a single device.</p>
<p>Setting up the work dispatcher requires providing it with lambda functions describing how to:</p><ol type="1">
<li>Actually run a sub-batch of work on a device</li>
<li>Reduce the final collection of sub-batches into a single result</li>
<li>Preprocess a sub-batch before running it (for example, send it to the device)</li>
<li>Postprocess a sub-batch before joining (for example, send it back to the cpu)</li>
<li>Initialize the device thread.</li>
</ol>
<p>NEML2 provides helper routines for assembling these lambdas for models returning the value of the model and/or the first derivatives of the results with respect to the inputs.</p>
<h1 class="doxsection"><a class="anchor" id="autotoc_md72"></a>
Work schedulers</h1>
<p>A work scheduler determines how to divide the full batch of model updates into smaller sub-batches and assign those to different compute devices. NEML2 provides several types of schedulers representing a combination of scheduling models:</p><ol type="1">
<li>A single CPU task has exclusive access to a single compute device.</li>
<li>A single CPU task has exclusive access to one or more compute devices.</li>
<li>Multiple CPU tasks share access to one or more compute devices (this is work in progress and not available in the current release of NEML2).</li>
</ol>
<p>A CPU task here can either mean a single program calling NEML2, for example the <span class="tt"><a class="el" href="namespaceneml2.html">neml2</a></span> executable provided with the NEML2 release, or a single MPI rank in a distributed parallel application. The third type of scheduler covers the most general heterogenous compute architecture, where a collection of local CPU threads have shared access to a collection of accelerator devices. However, the first two types of schedulers can also be used in distributed computing environments, with the caveat that each task/MPI rank must have <em>exclusive</em> access to a collection of accelerators.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md73"></a>
SimpleScheduler</h2>
<p>The <a class="el" href="syntax-schedulers.html#simplescheduler" title="SimpleScheduler">SimpleScheduler</a> is the simplest option. It dispatches work from a single instance of NEML2 to a single device. The user provides:</p><ol type="1">
<li>The torch-compatible name of the target device, e.g. <span class="tt">"cuda:0"</span>.</li>
<li>A device sub-batch size, which is the amount of work the scheduler will consider sending to the device at once.</li>
<li>Optionally, a device capacity. The dispatcher will continue to send sub-batches to the device until it is at capacity, then wait for it to complete some work before sending additional sub-batches. The default capacity is the sub-batch size, meaning the dispatcher will send a single sub-batch and wait for the device to finish before sending another.</li>
</ol>
<p>The animation below illustrates how the simple scheduler sends work to a device.</p>
<p> 

<div class="simple-scheduler-demo" style="width:95%"></div>
<div class="simple-scheduler-controls" style="text-align:center">
  <button class="play btn">Play</button>
  <button class="pause btn">Pause</button>
  <button class="restart btn">Restart</button>
</div>

</p>
<p>This animation shows the dispatcher sending sub-batches to the device until it reaches capacity. The dispatcher then blocks until the device completes a sub-batch, at which it sends another sub-batch to fill the device back to capacity. This pattern of work continues until the scheduler and dispatcher complete the entire, original batch of work.</p>
<p>This scheduling algorithm is useful:</p><ol type="1">
<li>To determine the optimal sub-batch size for a single device. Typically there is an optimal sub-batch size for a given model. The size will depend on the model, the delay in sending data to the device, and the device throughput. In practice it's best to determine that optimal size empircally by a numerical experiment and then reuse the optimal batch size in the more sophisticated scheduling algorithms.</li>
<li>In cases where each NEML2 instance, for example each MPI rank, only has exclusive access to a single accelerator. For example, running one MPI rank per node and each node has a single GPU.</li>
</ol>
<p>It also demonstrates the basic concepts applied in other schedulers.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md74"></a>
SimpleMPIScheduler</h2>
<p>The <a class="el" href="syntax-schedulers.html#simplempischeduler" title="SimpleMPIScheduler">SimpleMPIScheduler</a> is an extension of the <a class="el" href="syntax-schedulers.html#simplescheduler" title="SimpleScheduler">SimpleScheduler</a> which better distributes work in MPI parallel applications calling NEML2. This scheduler assigns each MPI rank a unique accelerator device out of a list of devices provided by the user. Each MPI rank sends work to its assigned device exclusively, using the same algorithm for work scheduling as in the <a class="el" href="syntax-schedulers.html#simplescheduler" title="SimpleScheduler">SimpleScheduler</a>. The difference in inputs between the <a class="el" href="syntax-schedulers.html#simplempischeduler" title="SimpleMPIScheduler">SimpleMPIScheduler</a> and the <a class="el" href="syntax-schedulers.html#simplescheduler" title="SimpleScheduler">SimpleScheduler</a> is just that the user now provides a list of devices, a list of sub-batch sizes, and (optionally), a list of capacities. Each item in the list is a single device available to MPI ranks.</p>
<p>This scheduler assigns a rank to a device by first forming a local MPI communicator over the MPI ranks running on a single compute node (determined by the hostname provided by the <span class="tt">MPI_Get_processor_name</span> function). Each MPI rank in the communicator is assigned one device from the list provided by the user. The user must provide at least as many devices as the local communicator has MPI ranks. This approach limits the number of MPI ranks a user can launch <em>per node</em> to the number of available accelerators. For example, if a compute node has one CPU with 16 threads and 8 GPU accelerators the host application can only run 8 MPI ranks per node. The scheduler will report an error if the host application tries to run it with more local ranks than user supplied devices. This often means the user will need to <a href="https://hpc-wiki.info/hpc/Binding/Pinning">pin ranks</a> to ensure their MPI application assigns only the required number of ranks per node.</p>
<p>This scheduler is useful for larger parallel jobs, but may limit the overall performance of the application as often there are more CPU cores available for MPI ranks than accelerators on a node.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md75"></a>
StaticHybridScheduler</h2>
<p>The <a class="el" href="syntax-schedulers.html#statichybridscheduler" title="StaticHybridScheduler">StaticHybridScheduler</a> allows a single instance of NEML2 to distribute work to many compute devices at once. The user provides a list of devices, sub-batch sizes, capacities, and (optionally) priorities. The scheduler will greedily assign work to fill up each device, using the priority if provided to determine in which order to dole out work. The work dispatcher will then run this work in parallel on all devices via the thread pool discussed above.</p>
<p>This scheduler currently provides the best throughput for cases where a single NEML2 instance has access to multiple devices. The device list can include the CPU itself so that the CPU thread running NEML2 can do work at the same time the accelerators are working on their sub-batches. We suggest the user determine the optimal sub-batch size for each device, for example using the <a class="el" href="syntax-schedulers.html#simplescheduler" title="SimpleScheduler">SimpleScheduler</a>, prior to running large jobs with this scheduling algorithm.</p>
<p>The animation below illustrates how the static hybrid scheduler sends work to multiple devices.</p>
<p> 

<div class="static-hybrid-scheduler-demo" style="width:95%"></div>
<div class="static-hybrid-scheduler-controls" style="text-align:center">
  <button class="play btn">Play</button>
  <button class="pause btn">Pause</button>
  <button class="restart btn">Restart</button>
</div>

</p>
<p>The downside to this scheduler is that it does not handle MPI parallelism. Distributed parallel programs invoking NEML2 can only use this scheduler if each MPI rank has exclusive access to all accelerators on a compute node, i.e. running one MPI rank per physical node.</p>
<h1 class="doxsection"><a class="anchor" id="autotoc_md76"></a>
Event tracing</h1>
<p>Work scheduling and dispatching can get complicated quickly as more sophisticated scheduling strategies are used, and asynchronous dispatching further builds upon such complexity. Benchmarking and profiling can give us a rough idea on whether the scheduler and dispatcher are coordinating as expected, by examining the wall time against theoretical bounds. However, such approach is less ideal especially in hybrid computing environments.</p>
<p>In addition to benchmarking and profiling, NEML2 offers the capability of logging events related to scheduling and dispatching. The events are logged into a <em>trace</em> file in the <a href="https://www.chromium.org/developers/how-tos/trace-event-profiling-tool">Chrome trace format</a>. The trace file is essentially a JSON array of events.</p>
<p>To enable event tracing, inside the input file, set <span class="tt">Schedulers/*/trace_file</span> to the path of the output trace file, i.e. <span class="tt">path/to/trace.json</span>. While the work dispatcher and scheduler are coordinating the tasks, key events are continuously written to the trace file. After all calculations are complete, the trace file can be visualized using many third-party tools:</p><ul>
<li><a href="chrome://tracing/">Chrome trace viewer</a>, the canonical Chrome trace file viewer.</li>
<li><a href="https://ui.perfetto.dev/">Perfetto</a>, the successor of Chrome trace viewer.</li>
<li><a href="https://www.speedscope.app/">Speedscope</a> with unique features such as "left heavy" and "sandwich" modes.</li>
</ul>
<p>Below is an example screenshot from the Chrome trace viewer:</p>
<div class="image">
<img src="perfetto.png" alt="" width="85%"/>
<div class="caption">
Perfetto trace viewer example</div></div>
     </div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
</div><!-- container -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.16.1 </li>
  </ul>
</div>
</body>
</html>
